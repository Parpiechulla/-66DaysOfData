DAY1: 
Today I picked up from where I stopped on Kaggle courses and learnt how to use pipelines to keep data preprocessing and ML modeling codes organized. I made a prediction on cost of housing based on a melbourne housing data i found on kaggle with a mean absolute error 16366.58824, which is an improvement on my previous score of 21217.91640 which put me in the top 17% of participants on the scoreboard. 
#66daysofdata #MachineLearning #DataScience

Course material: https://www.kaggle.com/alexisbcook/pipelines
Notebook: https://github.com/Parpiechulla/-66DaysOfData/blob/main/Pipeline%20tutorial.ipynb



DAY2:
Today I finished the 5th lesson of the kaggle intermediate machine learning course on cross-validation as a better measure for model performance. I donâ€™t have a full hang of it yet so I picked up this book to improve my ML foundation, itâ€™s looking like itâ€™s going to be a good read ðŸ˜ƒ.

Course Link: https://lnkd.in/gDFDWHz
Other resources: https://lnkd.in/gEvq-jv
#machinelearning #datascience #66daysofdata



Day3: 
- Finished the first chapter of the book from Day2. 
- built a simple model using "KNearestNeighborsClassifier.

I also now have a better understanding of the different type of supervised learning problems (Classification and Regression) and when to apply which

Notebook: https://github.com/Parpiechulla/-66DaysOfData/blob/main/Predictive%20analysis%20using%20KNeighborsClassifier.ipynb
Other resource: http://noracook.io/Books/Python/introductiontomachinelearningwithpython.pdf
